# -*- coding: utf-8 -*-
"""Fielders_d_i.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gU-wIRvjy_pNbXLpwCt7vEhEBs7-zpOq
"""

from google.colab import auth
auth.authenticate_user()
import gspread
from oauth2client.client import GoogleCredentials
gc = gspread.authorize(GoogleCredentials.get_application_default())

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1peLpNFoEu8NHtVPttJXz4-aScixYu5dh_-6gYPOi9rQ/edit#gid=670066504')

sheet = wb.worksheet('Fielding')

data = sheet.get_all_values()

df = pd.DataFrame(data)
df.columns = df.iloc[0]
df = df.iloc[1:]

df.head()

import sklearn
print(sklearn.__version__)

from sklearn.linear_model import LinearRegression
from matplotlib import pyplot

print(df.info())

df.__eq__('-').sum()

df.__eq__('').sum()

df.replace('-','',inplace = True)

df.__eq__('').sum()

df.replace('',np.nan,inplace = True)

df["Height (cm)"]= df["Height (cm)"].astype(float)

from statistics import mean
df["Height (cm)"].fillna(df["Height (cm)"].mean(),inplace = True)

df["Man of the match"]= df["Man of the match"].astype(float)

df["Man of the match"].fillna(0, inplace = True)

df["Winning_D/I"]= df["Winning_D/I"].astype(float)

df["Winning_D/I"].fillna(0, inplace = True)

df.head()

df["Inns"]= df["Inns"].astype(float)

df["Dis"]= df["Dis"].astype(float)
df["Ct"]= df["Ct"].astype(float)
df["St"]= df["St"].astype(float)
df["Ct Wk"]= df["Ct Wk"].astype(float)
df["Ct Fi"]= df["Ct Fi"].astype(float)
df["MD"]= df["MD"].astype(float)
df["MDct"]= df["MDct"].astype(float)
df["MDst"]= df["MDst"].astype(float)
df["D/I"]= df["D/I"].astype(float)

from sklearn.ensemble import RandomForestRegressor

feature_names = ["Man of the match", "Dis", "Height (cm)", "Ct","St", "Ct Wk", "Ct Fi", "MD", "MDct", "Inns", "MDst"]
X = df[feature_names]
Y = df["D/I"]

#split the data set as training set and test set randomly
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)

#apply scaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

modelc_lreg = LinearRegression()

modelc_lreg.fit(X_train, y_train)

importance_lreg = modelc_lreg.coef_

for i,v in enumerate(importance_lreg):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

print('Accuracy of Linear regression classifier on training set: {:.2f}'
     .format(modelc_lreg.score(X_train, y_train)))
print('Accuracy of Linear regression classifier on test set: {:.2f}'
     .format(modelc_lreg.score(X_test, y_test)))

pyplot.bar([x for x in range(len(importance_lreg))], importance_lreg)
pyplot.xticks(np.arange(len(feature_names)),feature_names,rotation='vertical')
pyplot.show()

modelrfc = RandomForestRegressor()
modelrfc.fit(X_train, y_train)
importancerfc = modelrfc.feature_importances_
for i,v in enumerate(importancerfc):
	print('Feature:%0d -> %s, Score: %.5f' % (i,feature_names[i],v))

pyplot.bar([x for x in range(len(importancerfc))], importancerfc)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of Linear regression classifier on training set: {:.2f}'
     .format(modelrfc.score(X_train, y_train)))
print('Accuracy of Linear regression classifier on test set: {:.2f}'
     .format(modelrfc.score(X_test, y_test)))

from xgboost import XGBRegressor
# define the model
modelxg = XGBRegressor()
# fit the model
modelxg.fit(X_train, y_train)
# get importance
importancexg = modelxg.feature_importances_
# summarize feature importance
for i,v in enumerate(importancexg):
	print('Feature: %0d, -> %s Score: %.5f' % (i,feature_names[i] ,v))
# plot feature importance
plt.bar([x for x in range(len(importancexg))], importancexg)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
plt.show()

print('Accuracy of xgboost classifier on training set: {:.2f}'
     .format(modelxg.score(X_train, y_train)))
print('Accuracy of xgboost classifier on test set: {:.2f}'
     .format(modelxg.score(X_test, y_test)))

from sklearn.neighbors import KNeighborsRegressor
from sklearn.inspection import permutation_importance

# define the model
knn = KNeighborsRegressor()
# fit the model
knn.fit(X_train, y_train)
# perform permutation importance
results = permutation_importance(knn, X_train, y_train, scoring='neg_mean_squared_error')
# get importance
importance_k = results.importances_mean
# summarize feature importance
for i,v in enumerate(importance_k):
	print('Feature: %0d, -> %s Score: %.5f' % (i,feature_names[i],v))
# plot feature importance
plt.bar([x for x in range(len(importance_k))], importance_k)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
plt.show()

print('Accuracy of knn classifier on training set: {:.2f}'
     .format(knn.score(X_train, y_train)))
print('Accuracy of knn classifier on test set: {:.2f}'
     .format(knn.score(X_test, y_test)))

from sklearn.tree import DecisionTreeRegressor
# from matplotlib import pyplot

# define the model
modelcart = DecisionTreeRegressor()
# fit the model
modelcart.fit(X_train, y_train)
# get importance
importancecart = modelcart.feature_importances_
# summarize feature importance
for i,v in enumerate(importancecart):
	print('Feature: %0d,-> %s Score: %.5f' % (i,feature_names[i],v))
# plot feature importance
pyplot.bar([x for x in range(len(importancecart))], importancecart)
pyplot.xticks(np.arange(len(feature_names)), feature_names,rotation='vertical')
pyplot.show()

print('Accuracy of cart regressor on training set: {:.2f}'
     .format(modelcart.score(X_train, y_train)))
print('Accuracy of cart regressor on test set: {:.2f}'
     .format(modelcart.score(X_test, y_test)))

Test_names = ['Linear regression', 'Randomforest', 'CART', 'Xgboost',
              'k-neighbors']
name_code = ['LR', 'RF', 'CART', 'xG', 'k-N']

training = []
test = []

training.append(modelc_lreg.score(X_train, y_train))
training.append(modelrfc.score(X_train, y_train)) 
training.append(modelcart.score(X_train, y_train))
training.append(modelxg.score(X_train, y_train))
training.append(knn.score(X_train, y_train))

test.append(modelc_lreg.score(X_test, y_test))
test.append(modelrfc.score(X_test, y_test)) 
test.append(modelcart.score(X_test, y_test))
test.append(modelxg.score(X_test, y_test))
test.append(knn.score(X_test, y_test))

plt.scatter(name_code,training,label='training')
plt.scatter(name_code,test,label='test')
plt.xlabel('Name of the test')
plt.ylabel('Accuracy for each test')
plt.legend()
plt.show()

"""XgBoost SELECTED!!!"""

A = np.ones([len(feature_names),len(feature_names)])
for j,p in enumerate(importancexg):
  for i,v in enumerate(importancexg):
    A[j,i] = float("{:.5f}".format(p/v))
    print('Importance of %s over %s is  Score: %.3f' % (feature_names[j],feature_names[i],p/v))

ar = np.array(A)
print(ar)

priority = []
for row in A:
 v = 1
 for i in row:
   v = v * i
 v = v ** (1/len(feature_names))
 priority.append(v)

for i in range(len(feature_names)):
  print(feature_names[i],priority[i])

pr = np.array(priority)
p = sum(pr)
print(p)

weights = []
for i in priority:
  value = float("{:.4f}".format(i/p))
  weights.append(value)

for i in range(len(feature_names)):
  print(feature_names[i],weights[i])

thisdict = {}
for i in range(len(feature_names)):
  thisdict[feature_names[i]] = weights[i]
print(thisdict)

print(df.info())

df['Fielders_score'] = df['Man of the match']*thisdict['Man of the match']+df['Dis']*thisdict['Dis']+df['Height (cm)']*thisdict['Height (cm)']+df['Ct']*thisdict['Ct']+df['St']*thisdict['St']+df['Ct Wk']*thisdict['Ct Wk']+df['Ct Fi']*thisdict['Ct Fi']+df['MD']*thisdict['MD']+df['MDct']*thisdict['MDct']+df['Inns']*thisdict['Inns']+df['MDst']*thisdict['MDst']

df.head(15)

df.tail(15)

final_df = df.copy()

final_df = final_df.sort_values(by=['Fielders_score'], ascending=False)

final_df.head(20)

df1 = final_df[['Player', 'Fielders_score']]

df1.head(20)

from google.colab import files
df1.to_csv('filders_diav_score.csv' , index=False)
files.download('filders_diav_score.csv')